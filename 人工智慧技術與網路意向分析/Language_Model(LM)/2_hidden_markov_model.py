# -*- coding: utf-8 -*-
"""2. Hidden Markov Model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UcIRDTonOPEe1r0_OMbnr93MbYet4lZW

# **語言模型：基於機率模型**


## Hidden Markov Model

目標：


*   根據任務內容，準備訓練資料集
*   使用 hmmlearn 套件
*   應用在想定的任務上


---
**今日任務：訓練中文斷詞**

使用 MultinomialHMM 類別

參數：

```
n_components : 共有幾個觀測狀態

```

成員資料／函式：


```
model.startprob_ : 起始機率
model.transmat_ : 轉換機率
model.emissionprob_ : 觀測機率
```
"""

# 安裝必要套件
!pip install hmmlearn==0.2.6
# 0.2.1 is OK.

from google.colab import drive
drive.mount('/content/drive')

# 請同學先把 as_data.zip 上傳到你的 google 雲端硬碟，再執行以下

# (1) 掛載 google drive，並找到你上傳的路徑
# (2) 複製 as_data.zip 到這個 VM 下
# (3) 解開 zip 檔
# (4) 移動所有的 .utf8 到 data 目錄
!cp /content/drive/MyDrive/Colab Notebooks/人工智慧技術與網路意向分析/Week 13/as_data.zip .

!unzip as_data.zip

!mkdir data

!mv *.utf8 data

#@title
# del config_instance
# del __corpus
# del __model

# 匯入必要套件
import logging

logger = logging.getLogger('maty_logger')
# 取代 print
logger.setLevel(logging.INFO)

# 設定檔

config_instance = None

class Config:

    def __init__(self):
        self.config_dict = {
            'segment': {
                'train_corpus_path': 'data/as_training.utf8',
                'test_corpus_path': 'data/as_test.utf8',
                'test_corpus_gold_path': 'data/as_testing_gold.utf8',

                'init_state_path': 'data/init_state.pkl',
                'trans_state_path': 'data/trans_state.pkl',
                'emit_state_path': 'data/emit_state.pkl',
            },
        }

    def get(self, section_name, arg_name):
        return self.config_dict[section_name][arg_name]


def get_config():
    global config_instance
    if not config_instance:
        config_instance = Config()
    return config_instance

import pickle
from collections import Counter


__corpus = None


# 'S' : 單字詞語
# 'B' : 複數字詞語 - 開始字
# 'M' : 複數字詞語 - 中間字
# 'E' : 複數字詞語 - 結束字

class TaskHandler:
    # trans_mat：狀態轉移矩陣，trans_mat[state1][state2] 表示 train data 由 state1 轉移到 state2 的次數。
    # emit_mat：觀測矩陣，emit_mat[state][char] 表示 training set 中 某字 標註為 state 的次數。
    # init_vec：初始向量，init_vec[state] 表示狀態 state 在 training set 中出現的次數。
    # state_count：狀態統計，state_count[state] 表示狀態 state 出現的次數。
    # word ：字詞集合。
    _words = []
    # 觀測狀態
    _states = []
    # 字典
    _vocab = set([])
    # 標點符號
    _puns = set(u"？?!！·【】、；，。、\s+\t+~@#$%^&*()_+{}|:\"<"
                u"~@#￥%……&*（）——+{}|：“”‘’《》>`\-=\[\]\\\\;',\./■")
    @classmethod
    def initialize(cls):
        """
        初始化
        """
        config = get_config()
        train_corpus_path = config.get('segment', 'train_corpus_path')
        cls.read_corpus_from_file(train_corpus_path)
        cls.gen_vocabs()

    @classmethod
    def is_puns(cls, c):
        """
        是否為標點符號
        """
        return c in cls._puns

    @classmethod
    def gen_vocabs(cls):
        """
        產生字典
        """
        cls._vocab = list(set(cls._words))+[u'<UNK>']
        logger.info('字典內容：{}'.format(cls._vocab))

    @classmethod
    def read_corpus_from_file(cls, file_path):
        """
        從檔案讀入語料
        """
        f = open(file_path, 'r', encoding = "UTF-8-sig")
        lines = f.readlines()
        for line in lines:
            #cls._words.extend([word for word in line.decode('gbk').strip().split(' ') if word and not cls.is_puns(word)])
            cls._words.extend([word for word in line.strip().split('\u3000') if word and not cls.is_puns(word)])
        f.close()
        logger.info('語料內容：{}'.format(cls._words))

    @classmethod
    def word_to_states(cls, word):
        """
        標記對應觀測狀態
        'S' : 單字詞語
        'B' : 複數字詞語 - 開始字
        'M' : 複數字詞語 - 中間字
        'E' : 複數字詞語 - 結束字
        """
        word_len = len(word)
        if word_len == 1:
            cls._states.append('S')
        else:
            state = ['M'] * word_len
            state[0] = 'B'
            state[-1] = 'E'
            cls._states.append(''.join(state))

    @classmethod
    def get_train_data(cls):
        """
        取得訓練資料
        """
        return cls._words
    @classmethod
    def get_vocabs(cls):
        """
        取得字典
        """
        return cls._vocab
    @classmethod
    def cal_init_state(cls):
        """
        設定起始機率
        """
        init_counts = {'S': 0.0, 'B': 0.0, 'M': 0.0, 'E': 0.0}
        for state in cls._states:
            init_counts[state[0]] += 1.0
        words_count = len(cls._words)
        # init_state = {k: log((v+1)/words_count) for k, v in init_counts.items()}
        init_state = {k: (v+1)/words_count for k, v in init_counts.items()}

        msg = f'[cal_init_state] words_count = {words_count} ; init_state = {init_state}'
        logger.info( msg )
        return init_state

    @classmethod
    def cal_trans_state(cls):
        """
        計算狀態轉移機率
        """
        trans_counts = {'S': {'S': 0.0, 'B': 0.0, 'M': 0.0, 'E': 0.0},
                        'B': {'S': 0.0, 'B': 0.0, 'M': 0.0, 'E': 0.0},
                        'M': {'S': 0.0, 'B': 0.0, 'M': 0.0, 'E': 0.0},
                        'E': {'S': 0.0, 'B': 0.0, 'M': 0.0, 'E': 0.0}}
        states = ''.join(cls._states)
        counter = Counter(states)
        for index in range(len(states)):
            if index+1 == len(states): continue
            trans_counts[states[index]][states[index+1]] += 1.0
        # trans_state = {k: {kk: log((vv+1)/counter[k]) for kk, vv in v.items()} for k, v in trans_counts.items()}
        trans_state = {k: {kk: (vv+1)/counter[k] for kk, vv in v.items()} for k, v in trans_counts.items()}
        msg = f'[cal_trans_state] trans_state = {trans_state} '
        logger.info( msg )
        return trans_state

    @classmethod
    def cal_emit_state(cls):
        """
        計算觀測機率
        """
        word_dict = {word: 0.0 for word in ''.join(cls._vocab)}
        emit_counts = {'S': dict(word_dict), 'B': dict(word_dict), 'M': dict(word_dict), 'E': dict(word_dict)}
        states = ''.join(cls._states)
        counter = Counter(states)
        for index in range(len(cls._states)):
            for i in range(len(cls._states[index])):
                emit_counts[cls._states[index][i]][cls._words[index][i]] += 1
        # emit_state = {k: {kk: log((vv+1)/counter[k]) for kk, vv in v.items()} for k, v in emit_counts.items()}
        emit_state = {k: {kk: (vv+1)/counter[k] for kk, vv in v.items()} for k, v in emit_counts.items()}
        msg = f'[cal_emit_state] emit_counts = {emit_counts} ;\n emit_state = {emit_state}'
        logger.info( msg )
        return emit_state

    @classmethod
    def cal_state(cls):
        """
        計算三種機率，完成後儲存結果
        """
        for word in cls._words:
            cls.word_to_states(word)
        init_state = cls.cal_init_state()
        trans_state = cls.cal_trans_state()
        emit_state = cls.cal_emit_state()
        cls.save_state(init_state, trans_state, emit_state)

    @classmethod
    def save_state_to_file(cls, content, path):
        """
        存檔
        """
        f = open(path, 'wb')
        pickle.dump(content, f)
        f.close()

    @classmethod
    def read_state_from_file(cls, state_path):
        """
        讀檔
        """
        #f = open(state_path, 'rb')
        #content = pickle.load(f)
        #f.close()
        content = ''
        with open(state_path, 'rb') as f:
            content = pickle.loads(f.read())
        return content

    @classmethod
    def save_state(cls, init_state, trans_state, emit_state):
        """
        儲存(三種機率)
        """
        config = get_config()
        init_state_path = config.get('segment', 'init_state_path')
        trans_state_path = config.get('segment', 'trans_state_path')
        emit_state_path = config.get('segment', 'emit_state_path')
        cls.save_state_to_file(init_state, init_state_path)
        cls.save_state_to_file(trans_state, trans_state_path)
        cls.save_state_to_file(emit_state, emit_state_path)

    @classmethod
    def get_state(cls, name):
        """
        讀取(三種機率)
        """
        config = get_config()
        if name == 'init':
            state_path = config.get('segment', 'init_state_path')
        elif name == 'trans':
            state_path = config.get('segment', 'trans_state_path')
        elif name == 'emit':
            state_path = config.get('segment', 'emit_state_path')
        else:
            raise ValueError('state name must in ["init", "trans", "emit"].')
        state = cls.read_state_from_file(state_path)
        return state

    @classmethod
    def process_content(cls, lines):
        return [''.join([word for word in line.strip() if not cls.is_puns(word)]) for line in lines]
        #return [''.join([word for word in line.decode('gbk').strip() if not cls.is_puns(word)]) for line in lines]

    @classmethod
    def get_test_corpus(cls, name):
        """
        讀取測試集、及 ground truth
        """
        config = get_config()
        if name == 'test':
            path = config.get('segment', 'test_corpus_path')
        elif name == 'test_gold':
            path = config.get('segment', 'test_corpus_gold_path')
        else:
            raise ValueError('test or test_gold')
        f = open(path, 'r', encoding='UTF-8-sig')
        lines = f.readlines()
        corpus = cls.process_content(lines)
        f.close()
        return corpus

    def __init__(self):
        raise Exception("This class have not element method.")


def get_task():
    """
    專門處理資料及統計相關事項
    """
    global __corpus
    if not __corpus:
        __corpus = TaskHandler
    return __corpus

import numpy as np
from hmmlearn.hmm import MultinomialHMM #, CategoricalHMM

__model = None

class HMMHandler:

    def __init__(self):
        self.corpus = get_task()
        self.states, self.init_p = self.get_init_state()
        self.trans_p = self.get_trans_state()
        self.vocabs, self.emit_p = self.get_emit_state()
        self.model = self.get_model()

    def get_init_state(self):
        """
        取得起始機率，轉為numpy形式
        """
        states = ['S', 'B', 'M', 'E']
        init_state = self.corpus.get_state('init')
        init_p = np.array([init_state[s] for s in states])
        return states, init_p

    def get_trans_state(self):
        """
        取得轉移機率，轉為numpy形式
        """
        trans_state = self.corpus.get_state('trans')
        #print('trans_state :', trans_state)
        trans_p = np.array([[trans_state[s][ss] for ss in self.states] for s in self.states])
        #trans_p = np.array([[round(trans_state[s][ss], 2) for ss in self.states] for s in self.states])
        # normalize the matrix
        #trans_p = np.zeros( (len(self.states), len(self.states)) )
        #for i, s in enumerate(self.states):
        #    print(trans_state[s])
        #    sum_row = sum(trans_state[s].values())
        #    for j, ss in enumerate(self.states):
        #        print(trans_state[s][ss])
        #        trans_p[i][j] = trans_state[s][ss]/ sum_row

        return trans_p

    def get_emit_state(self):
        """
        取得觀測機率，轉為numpy形式
        """
        emit_state = self.corpus.get_state('emit')
        vocabs = []
        for s in self.states:
            vocabs.extend([k for k, v in emit_state[s].items()])
        vocabs = list(set(vocabs))
        emit_p = np.array([[emit_state[s][w] for w in vocabs] for s in self.states])
        return vocabs, emit_p

    def get_model(self):
        """
        初始化hmm模型
        """
        model = MultinomialHMM(n_components=len(self.states),  verbose=True)
        #model = CategoricalHMM(n_components=len(self.states), verbose=True)
        model.startprob_ = self.init_p
        model.transmat_ = self.trans_p
        model.emissionprob_ = self.emit_p
        model.n_features = len(self.vocabs)
        return model

    def pre_process(self, word):
        """
        如果有字詞沒有在字典裡，設定為 <UNK>
        """
        if word in self.vocabs:
            return self.vocabs.index(word)
        else:
            return len(self.vocabs)-1

    def cut(self, sentence):
        """
        執行斷詞
        """
        seen_n = np.array([[self.pre_process(w) for w in sentence]]).T
        msg = f'[cut] Before model.decode = {seen_n} ; '
        logger.info( msg )
        log_p, b = self.model.decode(seen_n, algorithm='viterbi')
        #states = self.model.predict_proba(seen_n)
        #msg = f'[cut] predict states = {states} ;\n '
        msg = f'[cut] log_p : {log_p}, b = {[ self.states[s] for s in b ]}'
        logger.info( msg )

        states = list(map(lambda x: self.states[x], b))
        cut_sentence = ''
        for index in range(len(states)):
            if states[index] in ('S', 'E'):
                cut_sentence += sentence[index]+' '
            else:
                cut_sentence += sentence[index]
        return cut_sentence

    @staticmethod
    def stats(cut_corpus, gold_corpus):
        """
        測試集與 ground truth 比對；計算 accuracy, recall, and F1 score
        """
        success_count = 0
        cut_count = 0
        gold_count = 0
        for index in range(len(cut_corpus)):
            cut_sentence = cut_corpus[index].split('\u3000')
            gold_sentence = gold_corpus[index].split('\u3000')
            cut_count += len(cut_sentence)
            gold_count += len(gold_sentence)
            for word in cut_sentence:
                if word in gold_sentence:
                    success_count += 1
        recall = float(success_count)/float(gold_count)
        precision = float(success_count)/float(cut_count)
        f1 = (2*recall*precision)/(recall+precision)
        return [precision, recall, f1]

    def sentence2index(self, sentence, length):
        ans = np.zeros(length)
        #for word, idx in self.vocabs:
        for word in sentence:
            idx_in_vocabs = self.vocabs.index(word)
            #ans.append(idx_in_vocabs)
            ans[idx_in_vocabs] = 1
        print(ans.shape)
        return ans

    def test(self):
        """
        執行測試集驗證
        """
        test_corpus = self.corpus.get_test_corpus('test')
        msg = f'[test] test_corpus = {test_corpus} ;'
        logger.info( msg )

        gold_corpus = [sentence.replace('  ', ' ').strip() for sentence in self.corpus.get_test_corpus('test_gold') if sentence]
        cut_corpus = [self.cut(sentence).strip() for sentence in test_corpus if sentence]
        result = self.stats(cut_corpus, gold_corpus)
        return result


def get_model():
    """
    專門處理模型相關事項
    """
    global __model
    if not __model:
        __model = HMMHandler()
    return __model

help(MultinomialHMM)

# 建立語料相關的類別
my_task = get_task()
my_task.initialize()

# 計算機率資料
my_task.cal_state()

# 這個會跑很久，請同學有空試一下
my_model = get_model()
my_model.test()

my_model = get_model()

# 測試一句話的斷詞
#maty_test = '這是一句好話再試一下'
#maty_test = '哈囉你好嗎？好久不見衷心感謝期待再相逢'
maty_test = '九百九十九朵玫瑰'

my_model.cut(maty_test)

"""## Quiz - 2: 你順利建立 HMM 模型、並使用了這個模型嗎？請問你認為這個模型，可以做**什麼樣的應用**？**有什麼缺點**？"""

