# -*- coding: utf-8 -*-
"""2. 語音辨識

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eK-X9qTLOMQut7L-EIwHr3ay5TsYZWiT

## 範例：語音辨識



*   使用 huggingface 上的語音辨識模型
*   使用 speechbrain 套件
*   辨識新聞中語音，轉錄出文字

三立新聞片段:
https://drive.google.com/file/d/15qXci-z9-lZNhfnVCDSDbrM0K01UBUcu/view?usp=share_link
"""

# 先抓今天要用的影片
# 我用三立新聞片段

!wget --no-check-certificate "https://drive.google.com/uc?export=download&id=15qXci-z9-lZNhfnVCDSDbrM0K01UBUcu" -O 三立.mp4

# 如果要把檔案切小一點的話....
# 切10秒鐘就好
!ffmpeg -ss 00:00:00 -to 00:00:10 -i 三立.mp4 -c copy a_video.mp4

# 使用 ffmpeg 工具，把影音分離，存成單獨的聲音檔
# 不要影像,只要聲音
!ffmpeg -i a_video.mp4 -vn -acodec copy a_audio.mp4

# 不會用 ffmpeg 的話,可以再看一次它的參數及功能說明
!ffmpeg

"""(1) 使用 huggingface 上的語音辨識模型"""

# 安裝必要套件
!pip install transformers

import librosa
import torch
from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor

# 指定輸入聲音檔
myRecFile = 'a_audio.mp4' #'4999.wav' #'demo_1.wav'

# load audio
myaudio_input, mysample_rate = librosa.load(myRecFile, sr=16000)

from IPython.display import Audio  # colab 上的播放器；Jupyter應該也可以用

Audio(data=myaudio_input, rate=mysample_rate)

# 先用這個模型，轉錄文字
# 語音辨識
# 2. load pretrained model
# FOR English
#myprocessor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h")
#mymodel = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-base-960h")

# FOR 繁簡中文
myprocessor = Wav2Vec2Processor.from_pretrained("ydshieh/wav2vec2-large-xlsr-53-chinese-zh-cn-gpt")
mymodel = Wav2Vec2ForCTC.from_pretrained("ydshieh/wav2vec2-large-xlsr-53-chinese-zh-cn-gpt")

# pad input values and return pt tensor
myinput_values = myprocessor(myaudio_input, sampling_rate=mysample_rate, return_tensors="pt").input_values

# INFERENCE
# 3. retrieve logits & take argmax
logits = mymodel(myinput_values).logits
predicted_ids = torch.argmax(logits, dim=-1)

# transcribe
transcription = myprocessor.decode(predicted_ids[0])

print('Get transcription :', transcription)

"""（２）使用 speechbrain"""

# 安裝必要套件
!pip install speechbrain

from speechbrain.pretrained import EncoderDecoderASR

asr_model = EncoderDecoderASR.from_hparams(source="speechbrain/asr-transformer-aishell", savedir="pretrained_models/asr-transformer-aishell")
asr_model.transcribe_file('a_audio.mp4')

"""## Quiz-3: 請設定不同的語音片段，或重新錄製語音，並觀察哪些因素可能會影響辨識結果？"""

