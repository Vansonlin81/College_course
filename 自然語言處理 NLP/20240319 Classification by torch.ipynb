{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"19Onfn8UXYfoshOKhv93aDBQyoMdHCysl","timestamp":1710831658963}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 環境設定"],"metadata":{"id":"1ROUKrxILPes"}},{"cell_type":"code","source":["# 下載講師自製的 HappyML\n","import os\n","\n","if not os.path.isdir(\"HappyML\"):\n","  os.system(\"git clone https://github.com/cnchi/HappyML.git\")"],"metadata":{"id":"Uo6Eecz_PF93"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gIkluLyYLD-q"},"outputs":[],"source":["# 載入必要套件\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","\n","import HappyML.preprocessor as pp\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.init as init\n","from torch.utils.data import DataLoader, TensorDataset"]},{"cell_type":"code","source":["# 檢查是否有可用的 GPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"id":"dKyOl_1RFzNS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710833397946,"user_tz":-480,"elapsed":34,"user":{"displayName":"林柏亦","userId":"18385432373658038035"}},"outputId":"3467d751-7d10-4f27-f080-ad677d0c46fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"markdown","source":["# 資料集前處理"],"metadata":{"id":"3e8xKwl4Lb9c"}},{"cell_type":"code","source":["# 載入資料集\n","dataset = load_iris()"],"metadata":{"id":"sOk5K55qLfwS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 切分自變數與應變數\n","X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n","Y = pd.DataFrame(dataset.target, columns=['Iris_Type'])\n","Y_name = dataset.target_names.tolist()\n","\n","# 可試著印出 X, Y, Y_name 驗證結果\n","print(X, Y)"],"metadata":{"id":"_oJKIn2mMG1S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710833548263,"user_tz":-480,"elapsed":9,"user":{"displayName":"林柏亦","userId":"18385432373658038035"}},"outputId":"d5ec67bb-4bc4-4878-f66d-c45999f8b781"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n","0                  5.1               3.5                1.4               0.2\n","1                  4.9               3.0                1.4               0.2\n","2                  4.7               3.2                1.3               0.2\n","3                  4.6               3.1                1.5               0.2\n","4                  5.0               3.6                1.4               0.2\n","..                 ...               ...                ...               ...\n","145                6.7               3.0                5.2               2.3\n","146                6.3               2.5                5.0               1.9\n","147                6.5               3.0                5.2               2.0\n","148                6.2               3.4                5.4               2.3\n","149                5.9               3.0                5.1               1.8\n","\n","[150 rows x 4 columns]      Iris_Type\n","0            0\n","1            0\n","2            0\n","3            0\n","4            0\n","..         ...\n","145          2\n","146          2\n","147          2\n","148          2\n","149          2\n","\n","[150 rows x 1 columns]\n"]}]},{"cell_type":"code","source":["# 切分訓練集、測試集\n","X_train, X_test, Y_train, Y_test = pp.split_train_test(x_ary=X, y_ary=Y)\n","print(X_train, X_test, Y_train, Y_test)"],"metadata":{"id":"nD2htyQoPvXb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710833608325,"user_tz":-480,"elapsed":330,"user":{"displayName":"林柏亦","userId":"18385432373658038035"}},"outputId":"662ba55d-d311-4648-8a54-2a1e71547751"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n","113                5.7               2.5                5.0               2.0\n","45                 4.8               3.0                1.4               0.3\n","64                 5.6               2.9                3.6               1.3\n","147                6.5               3.0                5.2               2.0\n","119                6.0               2.2                5.0               1.5\n","..                 ...               ...                ...               ...\n","91                 6.1               3.0                4.6               1.4\n","49                 5.0               3.3                1.4               0.2\n","110                6.5               3.2                5.1               2.0\n","18                 5.7               3.8                1.7               0.3\n","88                 5.6               3.0                4.1               1.3\n","\n","[112 rows x 4 columns]      sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n","87                 6.3               2.3                4.4               1.3\n","132                6.4               2.8                5.6               2.2\n","42                 4.4               3.2                1.3               0.2\n","103                6.3               2.9                5.6               1.8\n","90                 5.5               2.6                4.4               1.2\n","47                 4.6               3.2                1.4               0.2\n","68                 6.2               2.2                4.5               1.5\n","101                5.8               2.7                5.1               1.9\n","137                6.4               3.1                5.5               1.8\n","100                6.3               3.3                6.0               2.5\n","122                7.7               2.8                6.7               2.0\n","14                 5.8               4.0                1.2               0.2\n","75                 6.6               3.0                4.4               1.4\n","136                6.3               3.4                5.6               2.4\n","72                 6.3               2.5                4.9               1.5\n","2                  4.7               3.2                1.3               0.2\n","44                 5.1               3.8                1.9               0.4\n","143                6.8               3.2                5.9               2.3\n","36                 5.5               3.5                1.3               0.2\n","115                6.4               3.2                5.3               2.3\n","123                6.3               2.7                4.9               1.8\n","23                 5.1               3.3                1.7               0.5\n","24                 4.8               3.4                1.9               0.2\n","39                 5.1               3.4                1.5               0.2\n","127                6.1               3.0                4.9               1.8\n","108                6.7               2.5                5.8               1.8\n","67                 5.8               2.7                4.1               1.0\n","77                 6.7               3.0                5.0               1.7\n","52                 6.9               3.1                4.9               1.5\n","62                 6.0               2.2                4.0               1.0\n","98                 5.1               2.5                3.0               1.1\n","126                6.2               2.8                4.8               1.8\n","95                 5.7               3.0                4.2               1.2\n","82                 5.8               2.7                3.9               1.2\n","60                 5.0               2.0                3.5               1.0\n","0                  5.1               3.5                1.4               0.2\n","128                6.4               2.8                5.6               2.1\n","106                4.9               2.5                4.5               1.7      Iris_Type\n","113          2\n","45           0\n","64           1\n","147          2\n","119          2\n","..         ...\n","91           1\n","49           0\n","110          2\n","18           0\n","88           1\n","\n","[112 rows x 1 columns]      Iris_Type\n","87           1\n","132          2\n","42           0\n","103          2\n","90           1\n","47           0\n","68           1\n","101          2\n","137          2\n","100          2\n","122          2\n","14           0\n","75           1\n","136          2\n","72           1\n","2            0\n","44           0\n","143          2\n","36           0\n","115          2\n","123          2\n","23           0\n","24           0\n","39           0\n","127          2\n","108          2\n","67           1\n","77           1\n","52           1\n","62           1\n","98           1\n","126          2\n","95           1\n","82           1\n","60           1\n","0            0\n","128          2\n","106          2\n"]}]},{"cell_type":"code","source":["# 特徵縮放\n","X_train, X_test = pp.feature_scaling(fit_ary=X_train, transform_arys=(X_train, X_test))\n","\n","# 可試著印出 X_train, X_test, Y_train, Y_test 驗證結果\n","print(X_train, X_test)"],"metadata":{"id":"hRlH8aHTP-TH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710833611749,"user_tz":-480,"elapsed":370,"user":{"displayName":"林柏亦","userId":"18385432373658038035"}},"outputId":"21a5da44-19cf-442d-b79b-959a18e8aaf0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n","113          -0.157339         -1.396168           0.741024          1.088726\n","45           -1.214654         -0.222213          -1.275041         -1.130690\n","64           -0.274818         -0.457004          -0.043001          0.174849\n","147           0.782497         -0.222213           0.853028          1.088726\n","119           0.195100         -2.100541           0.741024          0.435957\n","..                 ...               ...                ...               ...\n","91            0.312579         -0.222213           0.517017          0.305403\n","49           -0.979695          0.482160          -1.275041         -1.261244\n","110           0.782497          0.247369           0.797026          1.088726\n","18           -0.157339          1.656115          -1.107036         -1.130690\n","88           -0.274818         -0.222213           0.237008          0.174849\n","\n","[112 rows x 4 columns]      sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n","87            0.547538         -1.865750           0.405013          0.174849\n","132           0.665018         -0.691795           1.077035          1.349834\n","42           -1.684571          0.247369          -1.331043         -1.261244\n","103           0.547538         -0.457004           1.077035          0.827618\n","90           -0.392297         -1.161377           0.405013          0.044295\n","47           -1.449612          0.247369          -1.275041         -1.261244\n","68            0.430059         -2.100541           0.461015          0.435957\n","101          -0.039859         -0.926586           0.797026          0.958172\n","137           0.665018          0.012578           1.021033          0.827618\n","100           0.547538          0.482160           1.301042          1.741495\n","122           2.192250         -0.691795           1.693055          1.088726\n","14           -0.039859          2.125697          -1.387045         -1.261244\n","75            0.899976         -0.222213           0.405013          0.305403\n","136           0.547538          0.716951           1.077035          1.610941\n","72            0.547538         -1.396168           0.685022          0.435957\n","2            -1.332133          0.247369          -1.331043         -1.261244\n","44           -0.862215          1.656115          -0.995032         -1.000136\n","143           1.134935          0.247369           1.245040          1.480388\n","36           -0.392297          0.951742          -1.331043         -1.261244\n","115           0.665018          0.247369           0.909030          1.480388\n","123           0.547538         -0.926586           0.685022          0.827618\n","23           -0.862215          0.482160          -1.107036         -0.869582\n","24           -1.214654          0.716951          -0.995032         -1.261244\n","39           -0.862215          0.716951          -1.219040         -1.261244\n","127           0.312579         -0.222213           0.685022          0.827618\n","108           1.017456         -1.396168           1.189039          0.827618\n","67           -0.039859         -0.926586           0.237008         -0.216813\n","77            1.017456         -0.222213           0.741024          0.697064\n","52            1.252415          0.012578           0.685022          0.435957\n","62            0.195100         -2.100541           0.181006         -0.216813\n","98           -0.862215         -1.396168          -0.379012         -0.086259\n","126           0.430059         -0.691795           0.629020          0.827618\n","95           -0.157339         -0.222213           0.293010          0.044295\n","82           -0.039859         -0.926586           0.125004          0.044295\n","60           -0.979695         -2.570123          -0.099003         -0.216813\n","0            -0.862215          0.951742          -1.275041         -1.261244\n","128           0.665018         -0.691795           1.077035          1.219280\n","106          -1.097174         -1.396168           0.461015          0.697064\n"]}]},{"cell_type":"code","source":["# 將資料轉換成 PyTorch 張量\n","X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n","Y_train_tensor = torch.tensor(Y_train.values, dtype=torch.long)\n","Y_test_tensor = torch.tensor(Y_test.values, dtype=torch.long)\n","\n","# 可試著印出 X_train_tensor, X_test_tensor, Y_train_tensor, Y_test_tensor 驗證\n","print(X_train_tensor, X_test_tensor, Y_train_tensor, Y_test_tensor)"],"metadata":{"id":"j75TduUmQnjs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710833650538,"user_tz":-480,"elapsed":327,"user":{"displayName":"林柏亦","userId":"18385432373658038035"}},"outputId":"6463f751-af3b-42fc-fc63-8e7ca57d096f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.1573, -1.3962,  0.7410,  1.0887],\n","        [-1.2147, -0.2222, -1.2750, -1.1307],\n","        [-0.2748, -0.4570, -0.0430,  0.1748],\n","        [ 0.7825, -0.2222,  0.8530,  1.0887],\n","        [ 0.1951, -2.1005,  0.7410,  0.4360],\n","        [ 2.4272,  1.6561,  1.5250,  1.0887],\n","        [ 1.6049,  1.1865,  1.3570,  1.7415],\n","        [ 0.4301,  0.7170,  0.9650,  1.4804],\n","        [ 1.8398, -0.6918,  1.3570,  0.9582],\n","        [-0.5098,  0.7170, -1.1070, -1.2612],\n","        [-1.0972,  0.0126, -1.2190, -1.2612],\n","        [ 0.5475, -0.6918,  0.7970,  0.4360],\n","        [-0.9797,  0.9517, -1.1630, -0.7390],\n","        [ 1.2524,  0.0126,  0.7970,  1.4804],\n","        [-0.0399, -0.9266,  0.7970,  0.9582],\n","        [ 2.1923, -0.2222,  1.3570,  1.4804],\n","        [ 0.0776, -0.2222,  0.2930,  0.4360],\n","        [ 0.6650, -0.9266,  0.9090,  0.9582],\n","        [ 1.1349, -0.2222,  1.0210,  1.2193],\n","        [-0.5098, -0.2222,  0.4610,  0.4360],\n","        [-0.5098,  0.7170, -1.2190, -1.0001],\n","        [-1.4496,  0.0126, -1.2190, -1.2612],\n","        [ 1.7223, -0.4570,  1.4690,  0.8276],\n","        [ 0.1951, -0.2222,  0.6290,  0.8276],\n","        [-0.9797,  0.7170, -1.1630, -1.0001],\n","        [ 0.0776,  0.2474,  0.6290,  0.8276],\n","        [-0.3923, -1.6310,  0.0690, -0.0863],\n","        [-1.2147,  0.0126, -1.1630, -1.2612],\n","        [ 0.1951, -0.4570,  0.4610,  0.4360],\n","        [-0.1573,  3.0649, -1.2190, -1.0001],\n","        [ 1.1349, -0.6918,  0.6290,  0.3054],\n","        [-0.2748, -0.6918,  0.6850,  1.0887],\n","        [-0.1573, -0.4570,  0.2930,  0.1748],\n","        [ 0.1951, -0.9266,  0.7970,  0.5665],\n","        [-0.5098,  1.4213, -1.2190, -1.2612],\n","        [ 0.3126, -0.4570,  0.5730,  0.3054],\n","        [ 1.0175,  0.0126,  0.4050,  0.3054],\n","        [ 1.0175, -0.2222,  0.8530,  1.4804],\n","        [ 1.3699,  0.2474,  0.5730,  0.3054],\n","        [-0.2748, -0.9266,  0.2930,  0.1748],\n","        [-0.1573, -0.6918,  0.4610,  0.1748],\n","        [-1.5671, -1.8658, -1.3310, -1.1307],\n","        [-0.8622,  1.6561, -1.1630, -1.2612],\n","        [ 0.3126, -0.6918,  0.1810,  0.1748],\n","        [-0.9797,  0.9517, -1.3310, -1.1307],\n","        [-0.9797, -1.8658, -0.2110, -0.2168],\n","        [ 1.2524,  0.0126,  0.9650,  1.2193],\n","        [ 1.2524,  0.2474,  1.1330,  1.4804],\n","        [ 0.6650, -0.4570,  0.3490,  0.1748],\n","        [ 0.5475,  0.4822,  0.5730,  0.5665],\n","        [ 0.3126, -1.1614,  1.0770,  0.3054],\n","        [ 1.4874, -0.2222,  1.2450,  1.2193],\n","        [-0.5098,  1.8909, -1.3310, -1.0001],\n","        [ 0.6650,  0.2474,  0.4610,  0.4360],\n","        [-0.9797,  1.1865, -1.2750, -1.2612],\n","        [-0.9797,  0.2474, -1.3870, -1.2612],\n","        [-0.1573, -0.6918,  0.2370,  0.1748],\n","        [-0.0399, -1.1614,  0.1810,  0.0443],\n","        [-1.6846, -0.4570, -1.2750, -1.2612],\n","        [ 2.1923, -1.1614,  1.8051,  1.4804],\n","        [ 1.6049,  0.2474,  1.3010,  0.8276],\n","        [ 0.0776, -0.2222,  0.7970,  0.8276],\n","        [-0.2748, -1.3962,  0.1250, -0.0863],\n","        [-1.6846, -0.2222, -1.3310, -1.2612],\n","        [-0.3923,  2.5953, -1.2750, -1.2612],\n","        [ 0.9000, -0.4570,  0.5170,  0.1748],\n","        [-0.9797,  0.7170, -1.2190, -1.2612],\n","        [-0.3923, -1.3962,  0.1810,  0.1748],\n","        [-1.0972, -0.2222, -1.2750, -1.2612],\n","        [ 1.0175,  0.0126,  0.5730,  0.4360],\n","        [-0.8622,  0.9517, -1.2750, -1.1307],\n","        [-0.7447, -0.9266,  0.1250,  0.3054],\n","        [-0.9797, -0.2222, -1.1630, -1.2612],\n","        [ 2.1923,  1.6561,  1.6931,  1.3498],\n","        [-0.7447,  0.9517, -1.2190, -1.2612],\n","        [-0.0399, -0.6918,  0.7970,  1.6109],\n","        [ 0.7825, -0.6918,  0.5170,  0.4360],\n","        [-0.8622,  1.6561, -1.2190, -1.1307],\n","        [-0.8622,  1.4213, -1.2190, -1.0001],\n","        [-0.7447,  0.7170, -1.2750, -1.2612],\n","        [-1.0972,  1.1865, -1.2750, -1.3918],\n","        [ 1.0175,  0.0126,  1.0770,  1.6109],\n","        [-1.2147,  0.7170, -1.1630, -1.2612],\n","        [ 1.0175,  0.4822,  1.1330,  1.7415],\n","        [ 0.7825, -0.2222,  1.0210,  0.8276],\n","        [ 1.6049, -0.2222,  1.1890,  0.5665],\n","        [ 0.1951,  0.7170,  0.4610,  0.5665],\n","        [-0.3923, -1.6310,  0.0130, -0.2168],\n","        [-1.4496,  1.1865, -1.4990, -1.2612],\n","        [-1.0972,  0.0126, -1.2190, -1.3918],\n","        [ 0.5475, -1.3962,  0.7410,  0.9582],\n","        [-0.5098,  1.8909, -1.1070, -1.0001],\n","        [-0.6273,  1.4213, -1.2190, -1.2612],\n","        [-0.3923, -1.8658,  0.1810,  0.1748],\n","        [ 0.3126, -0.6918,  0.5730,  0.0443],\n","        [-1.2147, -0.2222, -1.2750, -1.3918],\n","        [-1.0972, -1.6310, -0.2110, -0.2168],\n","        [ 0.4301, -0.4570,  0.3490,  0.1748],\n","        [-0.7447,  2.3605, -1.2190, -1.3918],\n","        [-0.2748, -0.2222,  0.4610,  0.4360],\n","        [ 0.7825, -0.2222,  1.1890,  1.3498],\n","        [ 1.0175,  0.4822,  1.1330,  1.2193],\n","        [ 2.0748, -0.2222,  1.6371,  1.2193],\n","        [-0.1573, -1.1614, -0.0990, -0.2168],\n","        [-1.3321,  0.2474, -1.1630, -1.2612],\n","        [-1.8021, -0.2222, -1.4430, -1.3918],\n","        [-1.4496,  0.7170, -1.2750, -1.1307],\n","        [ 0.3126, -0.2222,  0.5170,  0.3054],\n","        [-0.9797,  0.4822, -1.2750, -1.2612],\n","        [ 0.7825,  0.2474,  0.7970,  1.0887],\n","        [-0.1573,  1.6561, -1.1070, -1.1307],\n","        [-0.2748, -0.2222,  0.2370,  0.1748]]) tensor([[ 0.5475, -1.8658,  0.4050,  0.1748],\n","        [ 0.6650, -0.6918,  1.0770,  1.3498],\n","        [-1.6846,  0.2474, -1.3310, -1.2612],\n","        [ 0.5475, -0.4570,  1.0770,  0.8276],\n","        [-0.3923, -1.1614,  0.4050,  0.0443],\n","        [-1.4496,  0.2474, -1.2750, -1.2612],\n","        [ 0.4301, -2.1005,  0.4610,  0.4360],\n","        [-0.0399, -0.9266,  0.7970,  0.9582],\n","        [ 0.6650,  0.0126,  1.0210,  0.8276],\n","        [ 0.5475,  0.4822,  1.3010,  1.7415],\n","        [ 2.1923, -0.6918,  1.6931,  1.0887],\n","        [-0.0399,  2.1257, -1.3870, -1.2612],\n","        [ 0.9000, -0.2222,  0.4050,  0.3054],\n","        [ 0.5475,  0.7170,  1.0770,  1.6109],\n","        [ 0.5475, -1.3962,  0.6850,  0.4360],\n","        [-1.3321,  0.2474, -1.3310, -1.2612],\n","        [-0.8622,  1.6561, -0.9950, -1.0001],\n","        [ 1.1349,  0.2474,  1.2450,  1.4804],\n","        [-0.3923,  0.9517, -1.3310, -1.2612],\n","        [ 0.6650,  0.2474,  0.9090,  1.4804],\n","        [ 0.5475, -0.9266,  0.6850,  0.8276],\n","        [-0.8622,  0.4822, -1.1070, -0.8696],\n","        [-1.2147,  0.7170, -0.9950, -1.2612],\n","        [-0.8622,  0.7170, -1.2190, -1.2612],\n","        [ 0.3126, -0.2222,  0.6850,  0.8276],\n","        [ 1.0175, -1.3962,  1.1890,  0.8276],\n","        [-0.0399, -0.9266,  0.2370, -0.2168],\n","        [ 1.0175, -0.2222,  0.7410,  0.6971],\n","        [ 1.2524,  0.0126,  0.6850,  0.4360],\n","        [ 0.1951, -2.1005,  0.1810, -0.2168],\n","        [-0.8622, -1.3962, -0.3790, -0.0863],\n","        [ 0.4301, -0.6918,  0.6290,  0.8276],\n","        [-0.1573, -0.2222,  0.2930,  0.0443],\n","        [-0.0399, -0.9266,  0.1250,  0.0443],\n","        [-0.9797, -2.5701, -0.0990, -0.2168],\n","        [-0.8622,  0.9517, -1.2750, -1.2612],\n","        [ 0.6650, -0.6918,  1.0770,  1.2193],\n","        [-1.0972, -1.3962,  0.4610,  0.6971]]) tensor([[2],\n","        [0],\n","        [1],\n","        [2],\n","        [2],\n","        [2],\n","        [2],\n","        [2],\n","        [2],\n","        [0],\n","        [0],\n","        [2],\n","        [0],\n","        [2],\n","        [2],\n","        [2],\n","        [1],\n","        [2],\n","        [2],\n","        [1],\n","        [0],\n","        [0],\n","        [2],\n","        [2],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [2],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [2],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [2],\n","        [2],\n","        [1],\n","        [1],\n","        [2],\n","        [2],\n","        [0],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [2],\n","        [2],\n","        [2],\n","        [1],\n","        [0],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [1],\n","        [0],\n","        [2],\n","        [0],\n","        [2],\n","        [1],\n","        [0],\n","        [0],\n","        [0],\n","        [0],\n","        [2],\n","        [0],\n","        [2],\n","        [2],\n","        [2],\n","        [1],\n","        [1],\n","        [0],\n","        [0],\n","        [2],\n","        [0],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [1],\n","        [0],\n","        [1],\n","        [2],\n","        [2],\n","        [2],\n","        [1],\n","        [0],\n","        [0],\n","        [0],\n","        [1],\n","        [0],\n","        [2],\n","        [0],\n","        [1]]) tensor([[1],\n","        [2],\n","        [0],\n","        [2],\n","        [1],\n","        [0],\n","        [1],\n","        [2],\n","        [2],\n","        [2],\n","        [2],\n","        [0],\n","        [1],\n","        [2],\n","        [1],\n","        [0],\n","        [0],\n","        [2],\n","        [0],\n","        [2],\n","        [2],\n","        [0],\n","        [0],\n","        [0],\n","        [2],\n","        [2],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [1],\n","        [2],\n","        [1],\n","        [1],\n","        [1],\n","        [0],\n","        [2],\n","        [2]])\n"]}]},{"cell_type":"markdown","source":["# 模型定義"],"metadata":{"id":"DLQdxAJAfReR"}},{"cell_type":"markdown","source":["## 定義代表模型的類別"],"metadata":{"id":"GUYUZ0fRmvYt"}},{"cell_type":"code","source":["class IrisModel(nn.Module):\n","\n","  # 定義神經網路每層架構\n","  def __init__(self):\n","    super(IrisModel, self).__init__()\n","\n","    # 先定義每個神經層\n","    self.fc1 = nn.Linear(4, 16)\n","    self.fc2 = nn.Linear(16, 16)\n","    self.fc3 = nn.Linear(16, 3)\n","\n","    # 接著初始化每個神經層的權重\n","    init.xavier_normal_(self.fc1.weight)\n","    init.xavier_normal_(self.fc2.weight)\n","    init.xavier_normal_(self.fc3.weight)\n","\n","  # 定義輸入值 x 如何一路計算到輸出值（正向傳播）\n","  def forward(self, x):\n","    x = torch.relu(self.fc1(x))\n","    x = torch.relu(self.fc2(x))\n","    x = self.fc3(x)\n","\n","    return x"],"metadata":{"id":"wMuWjrw-fXvW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 定義優化器與損失函數"],"metadata":{"id":"oscLtUJfmzGS"}},{"cell_type":"code","source":["# 將模型實體化\n","model = IrisModel().to(device)\n","\n","# 定義損失函數\n","criterion = nn.CrossEntropyLoss()\n","\n","# 定義優化器\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"metadata":{"id":"146ltgDmm8yO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 訓練模型"],"metadata":{"id":"nC20_mAfnXJp"}},{"cell_type":"code","source":["# 將資料集切割成數個 batch\n","batch_size = 32\n","\n","train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n","test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"P7LHUdHcgSmU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 開始訓練\n","epochs = 100\n","\n","for epoch in range(epochs):\n","  # 將模型設定為訓練模式\n","  model.train()\n","\n","  # 儲存猜對的數量 ＆ 完整數量\n","  correct = 0\n","  total = 0\n","\n","  # 取出一個 Batch 開始訓練\n","  for X_batch, Y_batch in train_loader:\n","    # 將 Batch 的資料轉換到 GPU 上\n","    X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","\n","    # 先把上一個 Batch 的梯度歸零\n","    optimizer.zero_grad()\n","\n","    # 計算輸出值\n","    Y_pred = model(X_batch)\n","    # 計算損失值\n","    loss = criterion(Y_pred, Y_batch.squeeze())\n","    # 根據損失值求微分找損失極小的權重（反向傳播）\n","    loss.backward()\n","    # 將求出來的權重實際更新上去\n","    optimizer.step()\n","\n","    # 計算第 1 軸的每一列，最大值之索引為何\n","    _, predicted = torch.max(Y_pred.data, 1)\n","    # 將這一批次有幾筆資料加入到 total 中\n","    total += Y_batch.size(0)\n","    # 計算猜對的數量（.item() 會協助取得純量）\n","    correct += (predicted == Y_batch.squeeze()).sum().item()\n","\n","  # 計算每個 epoch 的準確率\n","  accuracy = correct / total\n","  print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, Acc: {accuracy:.4f}')"],"metadata":{"id":"w9IKwcNQnbBv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710833423789,"user_tz":-480,"elapsed":1528,"user":{"displayName":"林柏亦","userId":"18385432373658038035"}},"outputId":"c70ecf46-8845-4517-fe3b-819b29ea787d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Loss: 1.1438, Acc: 0.1786\n","Epoch 2/100, Loss: 1.0637, Acc: 0.2232\n","Epoch 3/100, Loss: 1.0450, Acc: 0.3304\n","Epoch 4/100, Loss: 1.0285, Acc: 0.5089\n","Epoch 5/100, Loss: 0.9829, Acc: 0.6875\n","Epoch 6/100, Loss: 0.9602, Acc: 0.7768\n","Epoch 7/100, Loss: 0.9658, Acc: 0.8125\n","Epoch 8/100, Loss: 0.9203, Acc: 0.8393\n","Epoch 9/100, Loss: 0.8591, Acc: 0.8571\n","Epoch 10/100, Loss: 0.9191, Acc: 0.8750\n","Epoch 11/100, Loss: 0.8382, Acc: 0.9196\n","Epoch 12/100, Loss: 0.8267, Acc: 0.9643\n","Epoch 13/100, Loss: 0.7746, Acc: 0.9643\n","Epoch 14/100, Loss: 0.7951, Acc: 0.9643\n","Epoch 15/100, Loss: 0.7422, Acc: 0.9464\n","Epoch 16/100, Loss: 0.6602, Acc: 0.9286\n","Epoch 17/100, Loss: 0.7226, Acc: 0.9286\n","Epoch 18/100, Loss: 0.6190, Acc: 0.9107\n","Epoch 19/100, Loss: 0.7851, Acc: 0.8839\n","Epoch 20/100, Loss: 0.6686, Acc: 0.8839\n","Epoch 21/100, Loss: 0.5960, Acc: 0.8750\n","Epoch 22/100, Loss: 0.6535, Acc: 0.8750\n","Epoch 23/100, Loss: 0.5678, Acc: 0.8750\n","Epoch 24/100, Loss: 0.5993, Acc: 0.8839\n","Epoch 25/100, Loss: 0.5714, Acc: 0.8839\n","Epoch 26/100, Loss: 0.5196, Acc: 0.8750\n","Epoch 27/100, Loss: 0.4683, Acc: 0.8750\n","Epoch 28/100, Loss: 0.6500, Acc: 0.8571\n","Epoch 29/100, Loss: 0.5346, Acc: 0.8571\n","Epoch 30/100, Loss: 0.5007, Acc: 0.8571\n","Epoch 31/100, Loss: 0.5089, Acc: 0.8571\n","Epoch 32/100, Loss: 0.4059, Acc: 0.8571\n","Epoch 33/100, Loss: 0.3555, Acc: 0.8571\n","Epoch 34/100, Loss: 0.4982, Acc: 0.8571\n","Epoch 35/100, Loss: 0.4627, Acc: 0.8571\n","Epoch 36/100, Loss: 0.3178, Acc: 0.8571\n","Epoch 37/100, Loss: 0.3520, Acc: 0.8571\n","Epoch 38/100, Loss: 0.3905, Acc: 0.8571\n","Epoch 39/100, Loss: 0.5004, Acc: 0.8571\n","Epoch 40/100, Loss: 0.3793, Acc: 0.8571\n","Epoch 41/100, Loss: 0.4188, Acc: 0.8571\n","Epoch 42/100, Loss: 0.3827, Acc: 0.8839\n","Epoch 43/100, Loss: 0.3825, Acc: 0.8839\n","Epoch 44/100, Loss: 0.3816, Acc: 0.8839\n","Epoch 45/100, Loss: 0.4532, Acc: 0.8839\n","Epoch 46/100, Loss: 0.3053, Acc: 0.8929\n","Epoch 47/100, Loss: 0.2814, Acc: 0.8929\n","Epoch 48/100, Loss: 0.2241, Acc: 0.8929\n","Epoch 49/100, Loss: 0.3579, Acc: 0.8929\n","Epoch 50/100, Loss: 0.2760, Acc: 0.9018\n","Epoch 51/100, Loss: 0.3021, Acc: 0.9018\n","Epoch 52/100, Loss: 0.2846, Acc: 0.9018\n","Epoch 53/100, Loss: 0.4385, Acc: 0.9018\n","Epoch 54/100, Loss: 0.2901, Acc: 0.9018\n","Epoch 55/100, Loss: 0.3363, Acc: 0.9018\n","Epoch 56/100, Loss: 0.4617, Acc: 0.9018\n","Epoch 57/100, Loss: 0.3479, Acc: 0.9018\n","Epoch 58/100, Loss: 0.2993, Acc: 0.9107\n","Epoch 59/100, Loss: 0.2692, Acc: 0.9107\n","Epoch 60/100, Loss: 0.3374, Acc: 0.9107\n","Epoch 61/100, Loss: 0.2158, Acc: 0.9107\n","Epoch 62/100, Loss: 0.2916, Acc: 0.9107\n","Epoch 63/100, Loss: 0.3355, Acc: 0.9107\n","Epoch 64/100, Loss: 0.2942, Acc: 0.9107\n","Epoch 65/100, Loss: 0.3188, Acc: 0.9196\n","Epoch 66/100, Loss: 0.2699, Acc: 0.9196\n","Epoch 67/100, Loss: 0.4377, Acc: 0.9196\n","Epoch 68/100, Loss: 0.2131, Acc: 0.9196\n","Epoch 69/100, Loss: 0.2905, Acc: 0.9375\n","Epoch 70/100, Loss: 0.1829, Acc: 0.9375\n","Epoch 71/100, Loss: 0.2381, Acc: 0.9375\n","Epoch 72/100, Loss: 0.2692, Acc: 0.9375\n","Epoch 73/100, Loss: 0.2208, Acc: 0.9375\n","Epoch 74/100, Loss: 0.2431, Acc: 0.9286\n","Epoch 75/100, Loss: 0.2290, Acc: 0.9286\n","Epoch 76/100, Loss: 0.2067, Acc: 0.9375\n","Epoch 77/100, Loss: 0.2347, Acc: 0.9464\n","Epoch 78/100, Loss: 0.1142, Acc: 0.9375\n","Epoch 79/100, Loss: 0.1798, Acc: 0.9375\n","Epoch 80/100, Loss: 0.2312, Acc: 0.9375\n","Epoch 81/100, Loss: 0.1853, Acc: 0.9464\n","Epoch 82/100, Loss: 0.1175, Acc: 0.9464\n","Epoch 83/100, Loss: 0.2474, Acc: 0.9464\n","Epoch 84/100, Loss: 0.2609, Acc: 0.9464\n","Epoch 85/100, Loss: 0.1871, Acc: 0.9464\n","Epoch 86/100, Loss: 0.2155, Acc: 0.9464\n","Epoch 87/100, Loss: 0.1513, Acc: 0.9464\n","Epoch 88/100, Loss: 0.0919, Acc: 0.9375\n","Epoch 89/100, Loss: 0.1269, Acc: 0.9464\n","Epoch 90/100, Loss: 0.1262, Acc: 0.9554\n","Epoch 91/100, Loss: 0.1066, Acc: 0.9554\n","Epoch 92/100, Loss: 0.1617, Acc: 0.9554\n","Epoch 93/100, Loss: 0.1690, Acc: 0.9554\n","Epoch 94/100, Loss: 0.1691, Acc: 0.9554\n","Epoch 95/100, Loss: 0.1583, Acc: 0.9554\n","Epoch 96/100, Loss: 0.2376, Acc: 0.9554\n","Epoch 97/100, Loss: 0.1977, Acc: 0.9643\n","Epoch 98/100, Loss: 0.1515, Acc: 0.9643\n","Epoch 99/100, Loss: 0.0678, Acc: 0.9643\n","Epoch 100/100, Loss: 0.1524, Acc: 0.9643\n"]}]},{"cell_type":"markdown","source":["# 評估模型"],"metadata":{"id":"3jkz19kJCshH"}},{"cell_type":"code","source":["# 將模型切換為評估模式\n","model.eval()\n","\n","# 關閉 PyTorch 的梯度計算機制（Evaluation 時期不需要它）\n","with torch.no_grad():\n","\n","  # 儲存猜對的數量 ＆ 完整數量\n","  correct = 0\n","  total = 0\n","\n","  # 取出測試集的一個批次，開始測試\n","  for X_batch, Y_batch in test_loader:\n","    # 將 Batch 的資料轉換到 GPU 上\n","    X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","\n","    # 計算輸出值\n","    Y_pred = model(X_batch)\n","\n","    # 找到每一列預測機率最高的數值與其索引，即模型的預測類別。\n","    _, predicted = torch.max(Y_pred.data, 1)\n","    # 將這一批次有幾筆資料加入到 total 中\n","    total += Y_batch.size(0)\n","    # 計算猜對的數量（.item() 會協助取得純量）\n","    correct += (predicted == Y_batch.squeeze()).sum().item()\n","\n","  # 計算每個 epoch 的準確率\n","  print(f'Test Accuracy: {correct / total:.4f}')"],"metadata":{"id":"T2UxsjFDCvAf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710833423789,"user_tz":-480,"elapsed":12,"user":{"displayName":"林柏亦","userId":"18385432373658038035"}},"outputId":"d56fb256-9eec-4f05-8f9d-77aa6dbb14c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.8684\n"]}]}]}